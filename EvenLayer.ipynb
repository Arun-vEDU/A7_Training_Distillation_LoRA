{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datasets\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import random, math, time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id    target                                       comment_text  \\\n",
      "458232   806064  0.000000  It's difficult for many old people to keep up ...   \n",
      "272766   576402  0.166667  She recognized that her tiny-handed husband is...   \n",
      "339129   658508  0.000000  HPHY76,\\nGood for you for thinking out loud, w...   \n",
      "773565  5066714  0.500000  And I bet that in the day you expected your Je...   \n",
      "476233   828147  0.000000  Kennedy will add a much needed and scientifica...   \n",
      "\n",
      "        severe_toxicity  obscene  identity_attack    insult  threat  asian  \\\n",
      "458232              0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "272766              0.0      0.0              0.0  0.166667     0.0    NaN   \n",
      "339129              0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "773565              0.0      0.0              0.4  0.100000     0.0    0.0   \n",
      "476233              0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "\n",
      "        atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
      "458232      NaN  ...      160581  approved      0    0    0      1         0   \n",
      "272766      NaN  ...      150555  approved      0    0    0      2         0   \n",
      "339129      NaN  ...      154368  approved      0    0    0      0         0   \n",
      "773565      0.0  ...      322772  approved      0    0    0      4         2   \n",
      "476233      NaN  ...      161073  approved      0    0    1      0         0   \n",
      "\n",
      "        sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
      "458232              0.0                         0                         4  \n",
      "272766              0.0                         0                         6  \n",
      "339129              0.0                         0                         4  \n",
      "773565              0.0                         6                        10  \n",
      "476233              0.0                         0                         4  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "train_df_full = pd.read_csv('train.csv')  # Replace with the actual path to your dataset\n",
    "test_df_full = pd.read_csv('test.csv')    # Replace with the actual path to your dataset\n",
    "\n",
    "# Take 1% of the training dataset and assign it to train_df\n",
    "train_df= train_df_full.sample(frac=0.01, random_state=SEED)  # random_state ensures reproducibility\n",
    "\n",
    "# Take 1% of the test dataset and assign it to test_df\n",
    "test_df= test_df_full.sample(frac=0.01, random_state=SEED)  # random_state ensures reproducibility\n",
    "\n",
    "# Display the first few rows\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
      "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
      "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
      "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
      "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
      "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
      "       'other_sexual_orientation', 'physical_disability',\n",
      "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
      "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
      "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
      "       'identity_annotator_count', 'toxicity_annotator_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0.000000    12729\n",
      "0.166667     1421\n",
      "0.200000     1055\n",
      "0.300000      551\n",
      "0.400000      510\n",
      "            ...  \n",
      "0.506667        1\n",
      "0.876923        1\n",
      "0.148148        1\n",
      "0.770492        1\n",
      "0.095238        1\n",
      "Name: count, Length: 458, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    16677\n",
      "1     1372\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    " #Handle missing or invalid values in the 'comment_text' column\n",
    "train_df['comment_text'] = train_df['comment_text'].fillna('')  # Replace NaN with empty strings\n",
    "train_df['comment_text'] = train_df['comment_text'].astype(str)  # Ensure all values are strings\n",
    "\n",
    "# Preprocess the text (example: lowercase and remove special characters)\n",
    "train_df['comment_text'] = train_df['comment_text'].str.lower().replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# Apply a threshold of 0.5 to binarize the 'target' column\n",
    "train_df['target'] = (train_df['target'] >= 0.5).astype(int)\n",
    "\n",
    "# Check the distribution of the binarized labels\n",
    "print(train_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training texts: 14439\n",
      "Validation texts: 3610\n",
      "Training labels distribution:\n",
      " target\n",
      "0    13340\n",
      "1     1099\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['comment_text'], train_df['target'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Verify the split\n",
    "print(\"Training texts:\", len(train_texts))\n",
    "print(\"Validation texts:\", len(val_texts))\n",
    "print(\"Training labels distribution:\\n\", train_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ee5bc6401d4c598549f69b82cef781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa9fba1dfca4353a62acd4415949e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  # Replace with your model ID if different\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_dict({'text': train_texts, 'labels': train_labels.astype(int)})  # Ensure labels are integers\n",
    "val_dataset = Dataset.from_dict({'text': val_texts, 'labels': val_labels.astype(int)})  # Ensure labels are integers\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], max_length=128, truncation=True, padding='max_length')\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertConfig, BertModel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_train_dataset, shuffle=True, batch_size=32, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(tokenized_val_dataset, batch_size=32, collate_fn=data_collator)\n",
    "\n",
    "# Define the Teacher Model\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "teacher_model.to(device)\n",
    "teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student model initialized with even layers.\n"
     ]
    }
   ],
   "source": [
    "# Define the Student Model\n",
    "configuration = teacher_model.config.to_dict()\n",
    "configuration['num_hidden_layers'] //= 2  # Reduce the number of layers by half\n",
    "student_config = BertConfig.from_dict(configuration)\n",
    "student_model = AutoModelForSequenceClassification.from_config(student_config)\n",
    "student_model.to(device)\n",
    "\n",
    "# Function to Distill Weights (Odd Layers)\n",
    "def distill_odd_layers(teacher, student):\n",
    "    teacher_layers = teacher.bert.encoder.layer  # Access the encoder layers of the teacher\n",
    "    student_layers = student.bert.encoder.layer  # Access the encoder layers of the student\n",
    "\n",
    "    for i in range(len(student_layers)):\n",
    "        # Copy weights from odd layers of the teacher (1, 3, 5, 7, 9, 11)\n",
    "        student_layers[i].load_state_dict(teacher_layers[2 * i].state_dict())\n",
    "\n",
    "# Function to Distill Weights (Even Layers)\n",
    "def distill_even_layers(teacher, student):\n",
    "    teacher_layers = teacher.bert.encoder.layer  # Access the encoder layers of the teacher\n",
    "    student_layers = student.bert.encoder.layer  # Access the encoder layers of the student\n",
    "\n",
    "    for i in range(len(student_layers)):\n",
    "        # Copy weights from even layers of the teacher (2, 4, 6, 8, 10, 12)\n",
    "        student_layers[i].load_state_dict(teacher_layers[2 * i + 1].state_dict())\n",
    "\n",
    "# Distill Weights (Even Layers)\n",
    "\n",
    "distill_even_layers(teacher_model, student_model)\n",
    "print(\"Student model initialized with even layers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Functions\n",
    "criterion_div = nn.KLDivLoss(reduction='batchmean')\n",
    "criterion_cos = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer and Scheduler\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735b83a164ce4dde9837d1c2c9500f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/452 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.1635:\n",
      "  - Loss_cls: 0.3410\n",
      "  - Loss_div: 0.0643\n",
      "  - Loss_cos: 0.0854\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bb8ed4722b4ed7b48c7c4056a9da3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/452 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 2: Train loss 0.1542:\n",
      "  - Loss_cls: 0.3200\n",
      "  - Loss_div: 0.0757\n",
      "  - Loss_cos: 0.0670\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe51f8b57664c5c9ac933599e97b68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/452 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 3: Train loss 0.1411:\n",
      "  - Loss_cls: 0.2707\n",
      "  - Loss_div: 0.0893\n",
      "  - Loss_cos: 0.0635\n"
     ]
    }
   ],
   "source": [
    "# Lists to store losses for plotting\n",
    "train_losses = []\n",
    "train_losses_cls = []\n",
    "train_losses_div = []\n",
    "train_losses_cos = []\n",
    "eval_losses = []\n",
    "eval_accuracies = []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "    teacher_model.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_cls = 0\n",
    "    total_loss_div = 0\n",
    "    total_loss_cos = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass (Student)\n",
    "        student_outputs = student_model(**batch)\n",
    "\n",
    "        # Forward pass (Teacher)\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(**batch)\n",
    "\n",
    "        # Compute Losses\n",
    "        loss_cls = student_outputs.loss  # Classification loss\n",
    "        loss_div = criterion_div(\n",
    "            torch.log_softmax(student_outputs.logits / 2.0, dim=-1),\n",
    "            torch.softmax(teacher_outputs.logits / 2.0, dim=-1)\n",
    "        )  # Distillation loss\n",
    "        loss_cos = criterion_cos(\n",
    "            student_outputs.logits, teacher_outputs.logits, torch.ones(batch['input_ids'].size(0)).to(device)\n",
    "        )  # Cosine loss\n",
    "\n",
    "        # Total Loss\n",
    "        loss = (loss_cls + loss_div + loss_cos) / 3\n",
    "        total_loss += loss.item()\n",
    "        total_loss_cls += loss_cls.item()\n",
    "        total_loss_div += loss_div.item()\n",
    "        total_loss_cos += loss_cos.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Store losses for plotting\n",
    "    train_losses.append(total_loss / len(train_dataloader))\n",
    "    train_losses_cls.append(total_loss_cls / len(train_dataloader))\n",
    "    train_losses_div.append(total_loss_div / len(train_dataloader))\n",
    "    train_losses_cos.append(total_loss_cos / len(train_dataloader))\n",
    "\n",
    "    # Print training logs\n",
    "    print(f'Epoch at {epoch + 1}: Train loss {train_losses[-1]:.4f}:')\n",
    "    print(f'  - Loss_cls: {train_losses_cls[-1]:.4f}')\n",
    "    print(f'  - Loss_div: {train_losses_div[-1]:.4f}')\n",
    "    print(f'  - Loss_cos: {train_losses_cos[-1]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 3: Test Acc 0.9374\n",
      "Avg Metric 0.6249307479224376\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs_list, train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Train Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValidation Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Train Loss vs Validation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Arunya Senadeera\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arunya Senadeera\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\Arunya Senadeera\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\axes\\_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Arunya Senadeera\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\axes\\_base.py:486\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    483\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (2,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Evaluation\n",
    "student_model.eval()\n",
    "eval_loss = 0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = student_model(**batch)\n",
    "        loss_cls = outputs.loss\n",
    "        eval_loss += loss_cls.item()\n",
    "\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        total_correct += (predictions == batch['labels']).sum().item()\n",
    "        total_samples += batch['labels'].size(0)\n",
    "\n",
    "    eval_losses.append(eval_loss / len(val_dataloader))\n",
    "    eval_accuracy = total_correct / total_samples\n",
    "    eval_accuracies.append(eval_accuracy)\n",
    "\n",
    "    # Print evaluation logs\n",
    "    print(f\"Epoch at {epoch + 1}: Test Acc {eval_accuracy:.4f}\")\n",
    "\n",
    "# Print average evaluation metric\n",
    "print('Avg Metric', sum(eval_accuracies) / num_epochs)\n",
    "\n",
    "# Plotting\n",
    "epochs_list = range(1, num_epochs + 1)\n",
    "\n",
    "# Plot 1: Total Train Loss and Validation Loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs_list, train_losses, label='Total Train Loss', marker='o')\n",
    "plt.plot(epochs_list, eval_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Total Train Loss vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Train Loss Components (Loss_cls, Loss_div, Loss_cos)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs_list, train_losses_cls, label='Train Loss_cls', marker='o')\n",
    "plt.plot(epochs_list, train_losses_div, label='Train Loss_div', marker='o')\n",
    "plt.plot(epochs_list, train_losses_cos, label='Train Loss_cos', marker='o')\n",
    "plt.title('Train Loss Components')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Validation Loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs_list, eval_losses, label='Validation Loss', marker='o', color='red')\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
